{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9VCOst9uDje9Dwp9rOQK0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sidhtang/machine-learining-with-CN/blob/main/chatbot_assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "W9jtbLvPc_aP",
        "outputId": "972164ed-6251-42c4-9edb-eae637708d12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.9.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.11.10)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.5.2 (from gradio)\n",
            "  Downloading gradio_client-1.5.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.8.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.45.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.2->gradio) (14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.9.1-py3-none-any.whl (57.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.5.2-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.4/320.4 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.8.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.6 ffmpy-0.5.0 gradio-5.9.1 gradio-client-1.5.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.8.6 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.41.3 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import openai\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "class TechnicalAssessment:\n",
        "    \"\"\"Handles technical assessment logic and prompt engineering for different experience levels.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Define comprehensive assessment frameworks for different technologies and experience levels\n",
        "        self.assessment_frameworks = {\n",
        "            \"python\": {\n",
        "                \"junior\": {\n",
        "                    \"topics\": [\"basics\", \"data_structures\", \"oop\", \"error_handling\"],\n",
        "                    \"depth\": \"fundamental understanding\",\n",
        "                    \"practical_focus\": \"code reading and basic implementation\",\n",
        "                    \"questions\": [\n",
        "                        \"Explain how Python handles variable scope\",\n",
        "                        \"Describe the difference between lists and tuples\",\n",
        "                        \"How would you handle file operations in Python?\"\n",
        "                    ]\n",
        "                },\n",
        "                \"mid\": {\n",
        "                    \"topics\": [\"advanced_oop\", \"design_patterns\", \"testing\", \"performance\"],\n",
        "                    \"depth\": \"practical application\",\n",
        "                    \"practical_focus\": \"system design and optimization\",\n",
        "                    \"questions\": [\n",
        "                        \"How would you implement a singleton pattern in Python?\",\n",
        "                        \"Explain your approach to writing testable code\",\n",
        "                        \"How do you handle memory optimization in Python?\"\n",
        "                    ]\n",
        "                },\n",
        "                \"senior\": {\n",
        "                    \"topics\": [\"architecture\", \"scalability\", \"mentorship\", \"best_practices\"],\n",
        "                    \"depth\": \"expert understanding\",\n",
        "                    \"practical_focus\": \"complex system design and team leadership\",\n",
        "                    \"questions\": [\n",
        "                        \"How would you design a distributed system in Python?\",\n",
        "                        \"Explain your approach to code review and mentorship\",\n",
        "                        \"Describe your experience with system architecture decisions\"\n",
        "                    ]\n",
        "                }\n",
        "            },\n",
        "            \"javascript\": {\n",
        "                \"junior\": {\n",
        "                    \"topics\": [\"es6_basics\", \"dom\", \"async_basics\", \"error_handling\"],\n",
        "                    \"depth\": \"fundamental understanding\",\n",
        "                    \"practical_focus\": \"frontend functionality\",\n",
        "                    \"questions\": [\n",
        "                        \"Explain the difference between var, let, and const\",\n",
        "                        \"How does event delegation work?\",\n",
        "                        \"Describe your experience with async/await\"\n",
        "                    ]\n",
        "                },\n",
        "                \"mid\": {\n",
        "                    \"topics\": [\"advanced_async\", \"frameworks\", \"testing\", \"performance\"],\n",
        "                    \"depth\": \"practical application\",\n",
        "                    \"practical_focus\": \"complex applications\",\n",
        "                    \"questions\": [\n",
        "                        \"How do you handle state management in large applications?\",\n",
        "                        \"Explain your testing strategy for frontend code\",\n",
        "                        \"How do you optimize frontend performance?\"\n",
        "                    ]\n",
        "                },\n",
        "                \"senior\": {\n",
        "                    \"topics\": [\"architecture\", \"optimization\", \"security\", \"scalability\"],\n",
        "                    \"depth\": \"expert understanding\",\n",
        "                    \"practical_focus\": \"enterprise applications\",\n",
        "                    \"questions\": [\n",
        "                        \"How do you approach microfront-end architecture?\",\n",
        "                        \"Explain your strategy for securing frontend applications\",\n",
        "                        \"Describe your experience with large-scale JavaScript applications\"\n",
        "                    ]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def generate_assessment_questions(self, tech_stack: List[str], experience_years: int) -> Dict[str, List[str]]:\n",
        "        \"\"\"Generate relevant assessment questions based on technology and experience.\"\"\"\n",
        "        level = self._determine_level(experience_years)\n",
        "        questions = {}\n",
        "\n",
        "        for tech in tech_stack:\n",
        "            if tech.lower() in self.assessment_frameworks:\n",
        "                framework = self.assessment_frameworks[tech.lower()][level]\n",
        "                questions[tech] = framework['questions']\n",
        "\n",
        "        return questions\n",
        "\n",
        "    def _determine_level(self, years: int) -> str:\n",
        "        \"\"\"Determine candidate level based on years of experience.\"\"\"\n",
        "        if years < 3:\n",
        "            return \"junior\"\n",
        "        elif years < 7:\n",
        "            return \"mid\"\n",
        "        else:\n",
        "            return \"senior\"\n",
        "\n",
        "    def evaluate_response(self, response: str, level: str, tech: str) -> Dict:\n",
        "        \"\"\"Evaluate candidate responses using OpenAI.\"\"\"\n",
        "        evaluation_prompt = f\"\"\"\n",
        "        Evaluate the following response for a {level} {tech} position:\n",
        "\n",
        "        Response: {response}\n",
        "\n",
        "        Consider:\n",
        "        1. Technical accuracy\n",
        "        2. Depth of understanding\n",
        "        3. Communication clarity\n",
        "        4. Practical experience indicators\n",
        "\n",
        "        Provide a structured evaluation with scores and feedback.\n",
        "        \"\"\"\n",
        "\n",
        "        # This would integrate with OpenAI's API for evaluation\n",
        "        # Implement your evaluation logic here\n",
        "        return {\n",
        "            \"score\": 0.0,\n",
        "            \"feedback\": \"Evaluation pending implementation\"\n",
        "        }\n",
        "\n",
        "class CandidateManager:\n",
        "    \"\"\"Manages candidate data and persistence.\"\"\"\n",
        "\n",
        "    def __init__(self, data_directory: str = \"candidate_data\"):\n",
        "        self.data_directory = Path(data_directory)\n",
        "        self.data_directory.mkdir(exist_ok=True)\n",
        "        self.current_candidate = {}\n",
        "\n",
        "    def save_candidate(self, candidate_info: Dict) -> bool:\n",
        "        \"\"\"Save candidate information to persistent storage.\"\"\"\n",
        "        try:\n",
        "            candidate_id = self._generate_candidate_id(candidate_info)\n",
        "            file_path = self.data_directory / f\"{candidate_id}.json\"\n",
        "\n",
        "            data = {\n",
        "                \"candidate_info\": candidate_info,\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"assessment_status\": \"pending\"\n",
        "            }\n",
        "\n",
        "            with open(file_path, 'w') as f:\n",
        "                json.dump(data, f, indent=4)\n",
        "\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving candidate data: {e}\")\n",
        "            return False\n",
        "\n",
        "    def _generate_candidate_id(self, candidate_info: Dict) -> str:\n",
        "        \"\"\"Generate a unique candidate ID.\"\"\"\n",
        "        name = candidate_info.get('full_name', '').lower().replace(' ', '_')\n",
        "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "        return f\"{name}_{timestamp}\"\n",
        "\n",
        "    def get_candidate(self, candidate_id: str) -> Optional[Dict]:\n",
        "        \"\"\"Retrieve candidate information by ID.\"\"\"\n",
        "        file_path = self.data_directory / f\"{candidate_id}.json\"\n",
        "        try:\n",
        "            with open(file_path) as f:\n",
        "                return json.load(f)\n",
        "        except FileNotFoundError:\n",
        "            return None\n",
        "\n",
        "    def update_assessment_status(self, candidate_id: str, status: str) -> bool:\n",
        "        \"\"\"Update candidate assessment status.\"\"\"\n",
        "        candidate_data = self.get_candidate(candidate_id)\n",
        "        if candidate_data:\n",
        "            candidate_data['assessment_status'] = status\n",
        "            file_path = self.data_directory / f\"{candidate_id}.json\"\n",
        "            with open(file_path, 'w') as f:\n",
        "                json.dump(candidate_data, f, indent=4)\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "class EnhancedTalentScoutAssistant:\n",
        "    def __init__(self, api_key: str):\n",
        "        openai.api_key = api_key\n",
        "        self.conversation_history = []\n",
        "        self.current_state = \"greeting\"\n",
        "        self.current_candidate = {}\n",
        "\n",
        "    def _handle_state_based_response(self, message: str) -> str:\n",
        "        \"\"\"\n",
        "        Handle messages based on current conversation state with improved state transitions\n",
        "        and comprehensive input validation.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.current_state == \"greeting\":\n",
        "                self.current_state = \"info_collection\"\n",
        "                return (\"Hello! I'm your TalentScout technical assessment assistant. \"\n",
        "                       \"I'll help evaluate your technical skills. Could you please \"\n",
        "                       \"start by telling me your full name?\")\n",
        "\n",
        "            elif self.current_state == \"info_collection\":\n",
        "                if 'full_name' not in self.current_candidate:\n",
        "                    self.current_candidate['full_name'] = message\n",
        "                    return \"Thank you! Could you please share your email address?\"\n",
        "\n",
        "                elif 'email' not in self.current_candidate:\n",
        "                    if self._validate_email(message):\n",
        "                        self.current_candidate['email'] = message\n",
        "                        return \"Great! How many years of experience do you have in software development?\"\n",
        "                    return \"That doesn't look like a valid email address. Could you please check and try again?\"\n",
        "\n",
        "                elif 'experience' not in self.current_candidate:\n",
        "                    try:\n",
        "                        experience = float(message)\n",
        "                        if 0 <= experience <= 50:  # Reasonable range check\n",
        "                            self.current_candidate['experience'] = experience\n",
        "                            self.current_state = \"tech_stack\"\n",
        "                            return (\"Thank you! Now, please list the programming languages and technologies \"\n",
        "                                  \"you're proficient in (separated by commas):\")\n",
        "                        return \"Please enter a valid number of years between 0 and 50.\"\n",
        "                    except ValueError:\n",
        "                        return \"Please enter a valid number for your years of experience.\"\n",
        "\n",
        "                elif self.current_state == \"tech_stack\":\n",
        "                    technologies = [tech.strip() for tech in message.split(',')]\n",
        "                    if technologies:\n",
        "                        self.current_candidate['tech_stack'] = technologies\n",
        "                        self.current_state = \"position_interest\"\n",
        "                        return \"What position are you most interested in? (e.g., Frontend Developer, Backend Developer, Full Stack Developer)\"\n",
        "                    return \"Please enter at least one technology you're proficient in.\"\n",
        "\n",
        "                elif self.current_state == \"position_interest\":\n",
        "                    self.current_candidate['desired_position'] = message\n",
        "                    self.current_state = \"assessment_prep\"\n",
        "                    return self._prepare_assessment()\n",
        "\n",
        "            elif self.current_state == \"assessment_prep\":\n",
        "                self.current_state = \"assessment\"\n",
        "                return self._start_assessment()\n",
        "\n",
        "            elif self.current_state == \"assessment\":\n",
        "                return self._process_assessment_response(message)\n",
        "\n",
        "            return (\"I apologize, but I seem to have lost track of our conversation. \"\n",
        "                   \"Let's start over. Could you please tell me your name?\")\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"I encountered an error: {str(e)}. Let's try again with your last response.\"\n",
        "\n",
        "    def _validate_email(self, email: str) -> bool:\n",
        "        \"\"\"Validate email format using regex pattern.\"\"\"\n",
        "        import re\n",
        "        pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n",
        "        return bool(re.match(pattern, email))\n",
        "\n",
        "    def _prepare_assessment(self) -> str:\n",
        "        \"\"\"Prepare for the technical assessment phase.\"\"\"\n",
        "        return (f\"Thank you for providing your information, {self.current_candidate['full_name']}! \"\n",
        "                \"I'll now prepare some technical questions based on your experience level and tech stack. \"\n",
        "                \"Are you ready to begin the assessment? (Yes/No)\")\n",
        "\n",
        "    def _start_assessment(self) -> str:\n",
        "        \"\"\"Start the technical assessment with appropriate questions.\"\"\"\n",
        "        # Here you would generate questions based on tech stack and experience\n",
        "        return \"Let's start with your first technical question: [Your first question here]\"\n",
        "\n",
        "    def _process_assessment_response(self, response: str) -> str:\n",
        "        \"\"\"Process responses during the technical assessment phase.\"\"\"\n",
        "        # Here you would evaluate the response and provide the next question\n",
        "        return \"Thank you for your response. Here's your next question: [Next question here]\"\n",
        "\n",
        "    def create_interface(self) -> gr.Blocks:\n",
        "        \"\"\"Create Gradio interface with error handling and state management.\"\"\"\n",
        "        with gr.Blocks(theme=gr.themes.Soft()) as interface:\n",
        "            chatbot = gr.Chatbot(\n",
        "                label=\"TalentScout Hiring Assistant\",\n",
        "                height=600\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                msg = gr.Textbox(\n",
        "                    label=\"Type your message here...\",\n",
        "                    placeholder=\"Press Enter to send\",\n",
        "                    show_label=False\n",
        "                )\n",
        "                clear = gr.Button(\"Clear Conversation\")\n",
        "\n",
        "            def user_message(message: str, history: List) -> Tuple[str, List]:\n",
        "                try:\n",
        "                    if not message.strip():\n",
        "                        return \"\", history\n",
        "\n",
        "                    history.append((message, None))\n",
        "                    response = self._handle_state_based_response(message)\n",
        "                    history[-1] = (message, response)\n",
        "\n",
        "                    return \"\", history\n",
        "                except Exception as e:\n",
        "                    error_msg = f\"An error occurred: {str(e)}\"\n",
        "                    history.append((message, error_msg))\n",
        "                    return \"\", history\n",
        "\n",
        "            msg.submit(\n",
        "                fn=user_message,\n",
        "                inputs=[msg, chatbot],\n",
        "                outputs=[msg, chatbot]\n",
        "            )\n",
        "\n",
        "            clear.click(\n",
        "                fn=lambda: None,\n",
        "                inputs=None,\n",
        "                outputs=chatbot\n",
        "            )\n",
        "\n",
        "        return interface\n",
        "\n",
        "def main():\n",
        "    # Set a valid OpenAI API key in your environment or replace below\n",
        "    api_key = os.getenv('OPENAI_API_KEY', '')\n",
        "    assistant = EnhancedTalentScoutAssistant(api_key)\n",
        "    interface = assistant.create_interface()\n",
        "    interface.launch(share=True, show_error=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "7YbBsZTQPiAO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "cad5a5ca-e563-48a3-9e06-b6ef6bc4b20a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/components/chatbot.py:242: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://deefcb016eb6b736e5.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://deefcb016eb6b736e5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kj_g-aPPPiFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yvLmxZinYbgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0v8GHSHUYbiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O-20dxP1YbmO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}